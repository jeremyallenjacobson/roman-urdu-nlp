{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf073e2c",
   "metadata": {},
   "source": [
    "# Roman Urdu NLP\n",
    "#### **Author: Jeremy Jacobson**\n",
    "# Findings\n",
    "\n",
    "### Customer concerns\n",
    "The customer, a large multinational corporation, seeks to automatically identify the sentiment of the conversations of their customer base on social media. Many third party services exists for such a task, however languages such as Urdu do not fall under the umbrella of these services due to challenging idiosyncrasies such as a right to left writing style, Arabic script, and social media users' inconsistent transliteration of Urdu's arabic characters into the roman characters used when writing on social media. An example of these many transliterations is pictured below.\n",
    "\n",
    "![Arabic to Roman Urdu](https://ws-10-8-21.s3.amazonaws.com/arabic-to-roman.png)\n",
    "\n",
    "Urdu speakers represent a significant market in many countries beyond Pakistan, where it is the official language. For instance, there are more Urdu speakers in India than in Pakistan! [[University College London](https://www.ucl.ac.uk/atlas/urdu/language.html)] They number over one hundred million worldwide and widely utilize social media.\n",
    "\n",
    "The goal is to obtain a sentiment classifier that maximizes accuracy in order to provide a clear window into the social media conversations of the corporation's customer base. That said, the classifier uses three sentiments, Positive, Neutral, and Negative and of the three, knowing when their Urdu speaking customer base are expressing negative sentiment -- for instance when they are dissatisfied with the corporation or its services -- is of special interest. A key business outcome is therefore to accurately detect negative sentiment. Such a capability yields actionable data that the multinational can follow up on by targeting specific submarkets or even reaching out directly to their customer base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3e7d3e",
   "metadata": {},
   "source": [
    "### The data\n",
    "According to the authors of the [dataset](http://archive.ics.uci.edu/ml/datasets/Roman+Urdu+Data+Set), they write in [their paper](http://paper.ijcsns.org/07_book/201712/20171231.pdf) that the data is taken from multiple sources \"including twitter, urdubiography, IT\n",
    "Duniya, Reddit, Names4muslims, Pakish News and Shashca.com\". They have normalized the data to have a consistent format in Roman Urdu.\n",
    "\n",
    "The size of [the dataset](https://archive.ics.uci.edu/ml/datasets/Roman+Urdu+Data+Set) (`n=20000`) is well-suited for transformer based methods using pre-trained models (e.g. Hugging Face) or for tuning compositions of trained models.\n",
    "\n",
    "The dataset provided requires preprocessing. It includes text from a variety of sources, not only social media. Furthermore, some of the data is inconsistently labeled.\n",
    "\n",
    "Below is a sample of the data.\n",
    "![sample text](https://ws-10-8-21.s3.amazonaws.com/sample-text.png)\n",
    "Even to a reader unfamiliar with Roman Urdu, it is clear that there is a mixture of English and Urdu in the dataset which must be handled carefully if one if trying to transliterate Roman Urdu back into Arabic script.\n",
    "\n",
    "### Setting expectations\n",
    "It is important to consider that text of mixed sentiment will be especially challenging for a classifier with only the classes Negative, Neutral, and Positive. For example, widely used sentiment classification services such as Amazon Comprehend use a fourth class, 'mixed', when classifying sentiment. \n",
    "\n",
    "As an example of the difficulty of this task even for a human, consider this text from the sample we provided above.\n",
    "> I just read ummul khabees in the comment section and i am laughing so hard 😂😂\n",
    "\n",
    "It isn't obvious that this is of negative sentiment. The word ummul khabees [sic], often written 'Ummul Khabais', translates to Mother of Evils across the Islamic world. Clearly then, even for a human expert correctly interpreting the sentiment requires knowledge of the context. For instance, it could be that this user is laughing at a comment made by another user who called the corporation the Mother of Evils, in which case the text is defending the corporation and speaking positively of them. \n",
    "\n",
    "\n",
    "#### ML metrics and business outcomes\n",
    "Despite the limitations we just described, the opportunity is huge. Identifying sentiment in under-resourced languages like Roman Urdu can be a very manual process with employees combing forums and blogs. Even with a seemingly low negative predictive value of 0.5 on identifying negative text, such a task could be sped up by a factor of 2X! \n",
    "\n",
    "To understand why, let's consider a hypothetical day in the life of a social media communications manager for the Urdu market. By following this example, it will clarify how metrics for evaluating the multiclass classifier translate to a business context. Suppose that there are roughly 10000 Roman Urdu tweets to read each day, of which 2500 are negative about the corporation, and that the social media manager has time to read only 1000 each day. Manually, if they sample 1000 of the 10000, they will catch on average 250 negative tweets which they can then act on.\n",
    "\n",
    "Now, suppose they have a sentiment classifier which evaluates each of the tweets automatically and classifies roughly 2500 each day as negative and of those, 1250 are actually negative tweets, that is to say, \n",
    "$$\n",
    "\\text{Negative predictive value} = \\frac{\\text{TN}}{\\text{TN}+\\text{FN}} = 0.50\n",
    "$$\n",
    "If the communications manager instead spends their time reading 1000 only from the 1250 classified negative, they will catch on average 500 (0.50 * 1000) negative tweets. That is over 2X the 250 they would have found manually.\n",
    "\n",
    "#### State of the art from research papers\n",
    "Let's compare the performance of popular models that were trained on this same dataset for binary classification. In the paper,\n",
    "[Lexical Variation and Sentiment Analysis of Roman Urdu Sentences with Deep Neural Networks](https://thesai.org/Downloads/Volume11No2/Paper_90-Lexical_Variation_and_Sentiment_Analysis.pdf), published in 2020, the authors remove the rows labeled neutral from the data set we are working with and train various popular binary classifiers on it. Here are their results.\n",
    "![Table and text](https://ws-10-8-21.s3.amazonaws.com/table-and-text.png)\n",
    "\n",
    "### Our Model\n",
    "As a first step we worked on fine tuning a composition of ML services in order to establish a baseline for model performance before spending time and money training more sophisticated transformer based models.\n",
    "\n",
    "#### The baseline compositional model\n",
    "This model is simple to understand and implement. We first transliterate the Roman Urdu text in the dataset to Arabic characters. The latter is the only accepted input to Amazon translate for Urdu translation. Then we compose two state of the art ML services, Amazon Translate and Amazon Comprehend, in order to obtain a sentiment classifier for Roman Urdu text. \n",
    "#### Architecture diagram\n",
    "![diagram](https://ws-10-8-21.s3.amazonaws.com/diagram-baseline.png)\n",
    "\n",
    "In fact, after we began working on this, we were pleasantly surprised to find that Amazon Comprehend has a language detection API which automatically identifies text written in over 100 languages and returns the dominant language with a confidence score to support that a language is dominant. With text that is a mixture of Urdu and English, this was a useful tool for getting the sentiment correct.\n",
    "\n",
    "#### Pre-trained transformer model\n",
    " We first investigated replacing in our function above the Amazon Comprehend classifier with a pre-trained transformer model. The default in Hugging Face for sentiment analysis is [`distilbert-base-uncased-finetuned-sst-2-english`](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) which uses the DistilBERT architecture and has been fine-tuned on a dataset called SST-2 for sentiment analysis. We evaluated this and found performance comparable but slightly below the performance with Comprehend.\n",
    " \n",
    "#### Custom training on our dataset a pre-trained transformer model\n",
    "The baseline model does not allow for custom training. If that is an issue for the customer in the future then training on this dataset a pre-trained transformer model would be a good approach and that is the approach we take here.\n",
    "\n",
    "We investigated if training a transformer model classifier on the dataset improves our classifier. Specifically we used `DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')` and trained for one epoch.  Unfortunately, the limited training time (one epoch) was not sufficient and reduced performance of the pre-trained classifier.\n",
    "\n",
    "In a larger project, more time training could be spent to improve the performance of custom training.\n",
    "### Model accuracy \n",
    "Here are the metrics for the models.\n",
    "\n",
    "#### Baseline compositional model\n",
    "After limited processing of the dataset and fine-tuning of baseline model parameters (e.g. the parameter $p$ in the code section that controls how `Mixed` classes are distributed to the others) performance was very good. We took multiple samples of size 1000 from the dataset and on each evaluated the follow metrics. There is no need to split data into a training versus test set as the compositional model was not trained on this data. \n",
    "\n",
    "**Performance on the binary classification problem**\n",
    "\n",
    "| | precision  |  recall | f1-score |  support |\n",
    "| --- | --- | --- | --- |---|\n",
    "|    Negative  |     0.68  |    0.73  |    0.71    |   462 |\n",
    "|    Positive   |    0.75   |   0.71    |  0.73   |    538 |\n",
    "|    accuracy  |        |       |          0.72  |    1000 |\n",
    "|   macro avg  |     0.72   |   0.72  |    0.72  |    1000 |\n",
    "| weighted avg  |      0.72 |     0.72  |    0.72   |   1000 |\n",
    "\n",
    "\n",
    "*We see that the simple baseline model is already exceeding the performance of the deep learning models from the literature we cited earlier!*\n",
    "\n",
    "**Performance on the multiclass problem**\n",
    "\n",
    "| | precision  |  recall | f1-score |  support |\n",
    "| --- | --- | --- | --- |---|\n",
    "|    Negative  |     0.51  |    0.34  |    0.41    |   283 |\n",
    "|     Neutral  |     0.48   |   0.75  |    0.58   |    417|\n",
    "|    Positive   |    0.65   |   0.34    |  0.44   |    300 |\n",
    "|    accuracy  |        |       |          0.51  |    1000 |\n",
    "|   macro avg  |     0.55   |   0.48  |    0.48  |    1000 |\n",
    "| weighted avg  |      0.54 |     0.51  |    0.49   |   1000 |\n",
    "\n",
    "      \n",
    "Investigating negative predictive value further, we find that of the 190 examples labeled negative in the test set, the multiclass model correctly labeled 97 of them for a negative predictive value a.k.a. *precision* of 0.51. The proportion of negative text in the sample was 0.283.\n",
    "\n",
    "Let's put this again in the setting of a business use. If one is using the multiclass model to find negative text and only has time to read 200 phrases, then in a random sample of 200 the manual process would find 28% of 200, or 56. Reading only the 197 labeled negative by the classification model will lead to 97, increasing the throughput of negative examples found by a factor of 2.\n",
    "\n",
    "#### Transformer model\n",
    "We sampled 1000 values from the binarized dataset, that is, neutrals removed, for an evaluation dataset that would not be used in model training. Then we took the remaining rows and used them for an 80% train/test split. We evaluated on the evaluation data. The pre-trained model transformer without custom training was found to perform better and its performance is below.\n",
    "\n",
    "**Performance on the binary classification problem**\n",
    "\n",
    "| | precision  |  recall | f1-score |  support |\n",
    "| --- | --- | --- | --- |---|\n",
    "|    Negative  |     0.62  |    0.73  |    0.67    |   485 |\n",
    "|    Positive   |    0.69   |   0.57    |  0.62   |    515 |\n",
    "|    accuracy  |        |       |          0.65  |    1000 |\n",
    "|   macro avg  |     0.65   |   0.65  |    0.65  |    1000 |\n",
    "| weighted avg  |      0.66 |     0.65  |    0.65   |   1000 |\n",
    "  \n",
    "  \n",
    "Training on the dataset for one epoch was found to reduce performance of the pre-trained model! In a larger project, we would train for a longer time and would investigate training on the English translations of the Roman Urdu instead of the raw Roman Urdu itself. \n",
    "  \n",
    "# Recommendations\n",
    "There are no third party ML services for sentiment analysis in Roman Urdu. By composing existing ML services, we constructed a flexible Roman Urdu sentiment classifier suitable for multiclass or binary classification. Despite its simplicity, we have shown that its accuracy is competitive with state of the art models from current research. Indeed, we found when compared to binary classifiers in the literature that were trained on the same dataset, the model outperforms sophisticated machine learning models that were published as recently as 2020 (see [Lexical Variation and Sentiment Analysis of Roman Urdu Sentences with Deep Neural Networks](https://thesai.org/Downloads/Volume11No2/Paper_90-Lexical_Variation_and_Sentiment_Analysis.pdf)). \n",
    "\n",
    "When considering a machine learning solution there are many factors that must be considered in addition to performance. For instance, how will you maintain a model that has been deployed (e.g. model drift, debugging, retraining)? How frequently will the solution be used? Who are the users of the model and what is their technical level? We summarize the differences in the two models below.\n",
    "\n",
    "#### Composed model \n",
    "- [x] Easy to use and maintain\n",
    "- [x] Improves over time\n",
    "- [x] Competitive accuracy\n",
    "- [x] Competitive on negative identification\n",
    "- [ ] Improves with more data\n",
    "- [x] Scalable\n",
    "- [ ] Custom training (e.g. recognize company name)\n",
    "- [x] Cost efficient for sporadic use\n",
    "- [ ] Cost efficient for continous use\n",
    "\n",
    "#### Transformer model \n",
    "- [ ] Easy to use and maintain\n",
    "- [ ] Improves over time\n",
    "- [x] Competitive accuracy\n",
    "- [x] Competitive on negative identification\n",
    "- [x] Improves with more data\n",
    "- [x] Scalable\n",
    "- [x] Custom training possible (e.g. recognize company name)\n",
    "- [ ] Cost efficient for sporadic use\n",
    "- [x] Cost efficient for continous use\n",
    "\n",
    "#### Which model would be the most suitable choice for further work given the constraints imposed by the size of the dataset?\n",
    "\n",
    "If this is an experiment for the company that will see sporadic use, then the factors such as cost efficiency and ease of use clearly favor the composed model.   \n",
    "\n",
    "If the corporation expects that they will be using this classifier 24/7, serving inferences constantly throughout the day, then the costs of the ML services used in the composed model will exceed the costs of running an endpoint serving their own model 24/7. In this case, given the additional benefits outlined above, they should invest further in training a custom transformer model. \n",
    "\n",
    "Lastly, it is important to note that in either scenario, the composed model will have many uses. In a larger project, the limitations around the size of the dataset could be addressed by using the composed model for automatically labeling new data. In the way we described earlier, this would speed up manual labeling by a factor of 2X!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2613137",
   "metadata": {},
   "source": [
    "# Code\n",
    "We are in AWS Sagemaker and the kernel is `conda_pytorch_latest_p36`. When running the notebook the first time it is necessary to install the following packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690210e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awswrangler\n",
      "  Downloading awswrangler-2.12.1-py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 35.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opensearch-py<2.0.0,>=1.0.0\n",
      "  Downloading opensearch_py-1.0.0-py2.py3-none-any.whl (207 kB)\n",
      "\u001b[K     |████████████████████████████████| 207 kB 111.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas<1.2.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from awswrangler) (1.1.5)\n",
      "Requirement already satisfied: openpyxl<3.1.0,>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from awswrangler) (3.0.6)\n",
      "Collecting redshift-connector<2.1.0,>=2.0.887\n",
      "  Downloading redshift_connector-2.0.889-py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 8.1 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyarrow<5.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from awswrangler) (5.0.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from awswrangler) (1.19.5)\n",
      "Requirement already satisfied: xlwt<2.0.0,>=1.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from awswrangler) (1.3.0)\n",
      "Requirement already satisfied: xlrd<3.0.0,>=2.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from awswrangler) (2.0.1)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.16.8 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from awswrangler) (1.19.3)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.19.8 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from awswrangler) (1.22.3)\n",
      "Collecting pg8000<1.22.0,>=1.16.0\n",
      "  Downloading pg8000-1.21.3-py3-none-any.whl (34 kB)\n",
      "Collecting pymysql<1.1.0,>=0.9.0\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 4.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting requests-aws4auth<2.0.0,>=1.1.1\n",
      "  Downloading requests_aws4auth-1.1.1-py2.py3-none-any.whl (31 kB)\n",
      "Collecting progressbar2<4.0.0,>=3.53.3\n",
      "  Downloading progressbar2-3.55.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting jsonpath-ng<2.0.0,>=1.5.3\n",
      "  Downloading jsonpath_ng-1.5.3-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3<2.0.0,>=1.16.8->awswrangler) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3<2.0.0,>=1.16.8->awswrangler) (0.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<2.0.0,>=1.19.8->awswrangler) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<2.0.0,>=1.19.8->awswrangler) (2.8.2)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (4.4.2)\n",
      "Requirement already satisfied: ply in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (3.11)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (1.16.0)\n",
      "Requirement already satisfied: jdcal in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from openpyxl<3.1.0,>=3.0.0->awswrangler) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from openpyxl<3.1.0,>=3.0.0->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from opensearch-py<2.0.0,>=1.0.0->awswrangler) (2021.10.8)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas<1.2.0,>=1.1.0->awswrangler) (2021.3)\n",
      "Collecting scramp>=1.4.1\n",
      "  Downloading scramp-1.4.1-py3-none-any.whl (8.5 kB)\n",
      "Collecting python-utils>=2.3.0\n",
      "  Downloading python_utils-2.5.6-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from redshift-connector<2.1.0,>=2.0.887->awswrangler) (4.9.3)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from redshift-connector<2.1.0,>=2.0.887->awswrangler) (21.0)\n",
      "Requirement already satisfied: requests<2.26.1,>=2.23.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from redshift-connector<2.1.0,>=2.0.887->awswrangler) (2.26.0)\n",
      "Requirement already satisfied: lxml>=4.6.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from redshift-connector<2.1.0,>=2.0.887->awswrangler) (4.6.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift-connector<2.1.0,>=2.0.887->awswrangler) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests<2.26.1,>=2.23.0->redshift-connector<2.1.0,>=2.0.887->awswrangler) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests<2.26.1,>=2.23.0->redshift-connector<2.1.0,>=2.0.887->awswrangler) (3.3)\n",
      "Requirement already satisfied: asn1crypto>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from scramp>=1.4.1->pg8000<1.22.0,>=1.16.0->awswrangler) (1.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging->redshift-connector<2.1.0,>=2.0.887->awswrangler) (3.0.1)\n",
      "Installing collected packages: scramp, python-utils, requests-aws4auth, redshift-connector, pymysql, progressbar2, pg8000, opensearch-py, jsonpath-ng, awswrangler\n",
      "Successfully installed awswrangler-2.12.1 jsonpath-ng-1.5.3 opensearch-py-1.0.0 pg8000-1.21.3 progressbar2-3.55.0 pymysql-1.0.2 python-utils-2.5.6 redshift-connector-2.0.889 requests-aws4auth-1.1.1 scramp-1.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d6af0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-transliteration-api\n",
      "  Downloading google_transliteration_api-1.0.3-py3-none-any.whl (5.2 kB)\n",
      "Installing collected packages: google-transliteration-api\n",
      "Successfully installed google-transliteration-api-1.0.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google-transliteration-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6300f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting demoji\n",
      "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-resources->demoji) (3.6.0)\n",
      "Installing collected packages: importlib-resources, demoji\n",
      "Successfully installed demoji-1.1.0 importlib-resources-5.4.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9858538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 38.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 81.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.3.2-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (2020.11.13)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 104.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (4.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (2.26.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.1.1-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 1.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging>=20.0->transformers) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: filelock, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.3.2 huggingface-hub-0.1.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d159a9",
   "metadata": {},
   "source": [
    "We start below with our imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356bfe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import boto3\n",
    "import demoji\n",
    "from google.transliteration import transliterate_word, transliterate_text\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn.metrics\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b53de2",
   "metadata": {},
   "source": [
    "# Baseline model construction\n",
    "Below we implement a model for analyzing sentiment in Urdu phrases. Our model is the composition of two state of the art AWS models. We first translate the Urdu phrase to English using AWS Translate. Then the translated phrase is passed to AWS Comprehend to determine the sentiment. AWS Translate is built to take Urdu text that was written in an Arabic script. We have Urdu text written in Roman characters. So the first task is to transliterate the romanized text into arabic using a character mapping.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e7879",
   "metadata": {},
   "source": [
    "Now, let's write a function that does this and apply it to our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65bdbba",
   "metadata": {},
   "source": [
    "### Google transliterate\n",
    "Google had an API for transliteration. There is a Python package, [`google.transliteration`](https://pypi.org/project/google-transliteration-api/), which we use below. It is a Python library to use the Google Transliterate API, although it is not Google's official library since Google has deprecated the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db9388e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اسے سالگرہ پر خوبصورت تحفہ ملا\n"
     ]
    }
   ],
   "source": [
    "example_text = 'usay saalgira per khoobsurat tohfa mila'\n",
    "result = transliterate_text(example_text, lang_code='ur')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c228cec",
   "metadata": {},
   "source": [
    "Importantly, notice that the result from [ijunoon.com](https://www.ijunoon.com/transliteration/?type=1010202151424) are identical. \n",
    "\n",
    "اسے سالگرہ پر خوبصورت تحفہ ملا\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be39b86",
   "metadata": {},
   "source": [
    "The author's of the original dataset stated (see the paragraph before Table 2 from [their paper](http://paper.ijcsns.org/07_book/201712/20171231.pdf)) that they used [ijunoon.com](https://www.ijunoon.com/transliteration/?type=1010202151424) for transliteration. So our results should faithfully transliterate from Roman Urdu to Arabic Urdu.\n",
    "\n",
    "Next, we write functions for each of the steps in the model. First a function `roman_to_arabic` that converts the roman text to arabic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352f8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roman_to_arabic(phrase):\n",
    "    arabic = \"\"\n",
    "    result = []\n",
    "    for word in phrase.split():\n",
    "        if word not in re.findall(r'[.,!?;]',word):\n",
    "            try:\n",
    "                result.append(transliterate_word(word, 'ur', 1)[0])\n",
    "            except:\n",
    "                pass\n",
    "    arabic = ' '.join(result)\n",
    "    return arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e2fe95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'اسے سالگرہ پر خوبصورت تحفہ ملا'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roman_to_arabic(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76caba7b",
   "metadata": {},
   "source": [
    "Next, a function `urdu_to_english` which translate Urdu to English. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e511a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def urdu_to_english(arabic_urdu):\n",
    "    translate = boto3.client(service_name='translate', region_name='us-east-1', use_ssl=True)\n",
    "    english = \"\"\n",
    "    try:\n",
    "        result = translate.translate_text(Text=arabic_urdu, \n",
    "            SourceLanguageCode=\"ur\", TargetLanguageCode=\"en\")\n",
    "        english = result.get('TranslatedText')\n",
    "    except:\n",
    "        pass\n",
    "    return english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a6755",
   "metadata": {},
   "source": [
    "Let's test it. In the paper [Lexical Variation and Sentiment Analysis of Roman Urdu Sentences with Deep Neural Networks](https://thesai.org/Downloads/Volume11No2/Paper_90-Lexical_Variation_and_Sentiment_Analysis.pdf) it is translated as *He got a beautiful birthday present*. Here is our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d0e0942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She got a beautiful gift on the birthday'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_to_english('اسے سالگرہ پر خوبصورت تحفہ ملا')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a420f7d",
   "metadata": {},
   "source": [
    "Lastly, we write `sentiment_english` which is accepts English text and classifies it as 'Negative', 'Neutral', or 'Positive'. The default behavior of Comprehend is to use 4 classes, the additional one being 'Mixed'. We reassign the confidence score given to 'Mixed'. The extent to which the class `Mixed` is distributed to the `Neutral` class can be controlled with the parameter `p` and we split the remainder among the other classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "767ec8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_english(english_text, p =0.0):\n",
    "    comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')\n",
    "    sent_formatted = \"\"\n",
    "    try:\n",
    "        sent = comprehend.detect_sentiment(Text=english_text, LanguageCode='en')['Sentiment']\n",
    "        sent_formatted = sent[0]+sent[1:].lower()\n",
    "        if sent_formatted == \"Mixed\": # Split Mixed score into parts, add to others\n",
    "            results = comprehend.detect_sentiment(Text=english_text, LanguageCode='en')['SentimentScore']\n",
    "            results['Negative'] = results['Negative']+results['Mixed']*((1-p)/2)\n",
    "            results['Positive'] = results['Positive']+results['Mixed']*((1-p)/2)\n",
    "            results['Neutral'] = results['Neutral']+results['Mixed']*p\n",
    "            del results['Mixed']\n",
    "            results_s = sorted(results.items(), key=lambda x: x[1],reverse=True)\n",
    "            sent_formatted = results_s[0][0]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return sent_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2133ca",
   "metadata": {},
   "source": [
    "Below we refactor the function to be a binary classifier. We assign it the highest confidence class after removing the `Mixed` and `Neutral` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "430f6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_sentiment_english(english_text, p =0.0):\n",
    "    comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')\n",
    "    sent_formatted = \"\"\n",
    "    try:\n",
    "        sent = comprehend.detect_sentiment(Text=english_text, LanguageCode='en')['Sentiment']\n",
    "        sent_formatted = sent[0]+sent[1:].lower()\n",
    "        if sent_formatted == 'Mixed' or 'Neutral': # Add Mixed and neutral score to others\n",
    "            results = comprehend.detect_sentiment(Text=english_text, LanguageCode='en')['SentimentScore']\n",
    "            del results['Mixed']\n",
    "            del results['Neutral']\n",
    "            results_s = sorted(results.items(), key=lambda x: x[1],reverse=True)\n",
    "            sent_formatted = results_s[0][0]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return sent_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2be48d",
   "metadata": {},
   "source": [
    "## Example\n",
    "Let's test it on one of the rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f96d1ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ap ka nam kya hai\n",
      "Transliterated to Arabic: اپ کا نام کیا ہے\n",
      "English translation: What is your name\n",
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "print('Original: ap ka nam kya hai')\n",
    "arabic_urdu = roman_to_arabic('ap ka nam kya hai')\n",
    "print(f'Transliterated to Arabic: {arabic_urdu}')\n",
    "english_urdu = urdu_to_english(arabic_urdu)\n",
    "print(f'English translation: {english_urdu}')\n",
    "sentiment = sentiment_english(english_urdu)\n",
    "print(f'Sentiment: {sentiment}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb5041",
   "metadata": {},
   "source": [
    "Now, let's compose these functions into the model function which we can use to determine the sentiment of a Roman Urdu phrase. In order to avoid transliterating an English phrase into Arabic characters, we first use Comprehend to detect the dominant language in  the phrase. If English, we pass it directly to Comprehend to get the sentiment. Otherwise, we remove emojis (which the transliterate function doesn't handle)  and then pass it through the composition of the functions we wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc7b49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_roman_urdu(phrase):\n",
    "    sentiment = \"\"\n",
    "    \n",
    "    comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')\n",
    "    try:\n",
    "        response = comprehend.detect_dominant_language(Text=phrase)\n",
    "        dominant_language = response['Languages'][0]['LanguageCode']\n",
    "    except:\n",
    "        sentiment = \"dominant-language-error\"\n",
    "        dominant_language = ''\n",
    "        \n",
    "    if dominant_language == 'en': # apply comprehend directly if English\n",
    "        sentiment = sentiment_english(phrase)\n",
    "    else: #remove emojis, transliterate to arabic, translate, get sentiment\n",
    "        try:\n",
    "            phrase = demoji.replace(phrase) # remove emojis\n",
    "            arabic_urdu = roman_to_arabic(phrase)\n",
    "            english_urdu = urdu_to_english(arabic_urdu)\n",
    "            sentiment = sentiment_english(english_urdu)\n",
    "        except:\n",
    "            sentiment = \"error\"\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8c4e31",
   "metadata": {},
   "source": [
    "We also refactor this function above into a binary classifier below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "366fab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_sentiment_roman_urdu(phrase):\n",
    "    sentiment = \"\"\n",
    "    \n",
    "    comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')\n",
    "    try:\n",
    "        response = comprehend.detect_dominant_language(Text=phrase)\n",
    "        dominant_language = response['Languages'][0]['LanguageCode']\n",
    "    except:\n",
    "        sentiment = \"dominant-language-error\"\n",
    "        dominant_language = ''\n",
    "        \n",
    "    if dominant_language == 'en': # apply comprehend directly if English\n",
    "        sentiment = binary_sentiment_english(phrase)\n",
    "    else: #remove emojis, transliterate to arabic, translate, get sentiment\n",
    "        try:\n",
    "            phrase = demoji.replace(phrase) # remove emojis\n",
    "            arabic_urdu = roman_to_arabic(phrase)\n",
    "            english_urdu = urdu_to_english(arabic_urdu)\n",
    "            sentiment = binary_sentiment_english(english_urdu)\n",
    "        except:\n",
    "            sentiment = \"error\"\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da6fcb",
   "metadata": {},
   "source": [
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db88e180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_roman_urdu('ap ka nam kya hai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e12ff09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_sentiment_roman_urdu('ap ka nam kya hai')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a88577",
   "metadata": {},
   "source": [
    "## Transformer model construction\n",
    "We try with the default Hugging face default `Transformers` classifier for sentiment analysis. As we mentioned earlier, the default in Hugging Face for sentiment analysis is [`distilbert-base-uncased-finetuned-sst-2-english`](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) and that it was what we are applying using the `classifier` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b895b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76cfe052372455d829837dca3206a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dea91830a0450d818e99ed35476fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b384f34a3c4f81bfbc793ffc9985e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60edeb4eae714192b6acd2b7e3da7356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')\n",
    "def binary_sentiment_english_HF(english_text):\n",
    "    \n",
    "    sent_formatted = \"\"\n",
    "    try:\n",
    "        result = classifier(english_text)[0]\n",
    "        sent = result['label']\n",
    "        sent_formatted = sent[0]+sent[1:].lower()\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return sent_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea5740",
   "metadata": {},
   "source": [
    "Then we swap this in to the function which takes roman Urdu as input and classifies the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6a4c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_sentiment_roman_urdu_HF(phrase):\n",
    "    sentiment = \"\"\n",
    "    # first detect language\n",
    "    comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')\n",
    "    try:\n",
    "        response = comprehend.detect_dominant_language(Text=phrase)\n",
    "        dominant_language = response['Languages'][0]['LanguageCode']\n",
    "    except:\n",
    "        sentiment = \"dominant-language-error\"\n",
    "        dominant_language = ''\n",
    "        \n",
    "    if dominant_language == 'en': # apply transformer directly if English\n",
    "        sentiment = binary_sentiment_english_HF(phrase)\n",
    "    else: #remove emojis, transliterate to arabic, translate, get sentiment\n",
    "        try:\n",
    "            phrase = demoji.replace(phrase) # remove emojis\n",
    "            arabic_urdu = roman_to_arabic(phrase)\n",
    "            english_urdu = urdu_to_english(arabic_urdu)\n",
    "            sentiment = binary_sentiment_english_HF(english_urdu)\n",
    "        except:\n",
    "            sentiment = \"error\"\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437e0093",
   "metadata": {},
   "source": [
    "We can see how it works below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db2a521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_sentiment_roman_urdu_HF('I love it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3821b1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998799562454224}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('I love it')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e8a1a",
   "metadata": {},
   "source": [
    "#### Will training make a difference?\n",
    "The dataset we are working with is in fact a [Hugging Face dataset](https://huggingface.co/datasets/roman_urdu). We already cleaned our data, so to ensure a fair comparison we load our cleaned dataset instead. We remove 1000 rows from the *binarized* dataset at the end of the notebook in the testing data section. Below we load that data and split the remainder into a train/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "063781d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_t_1000 = wr.s3.read_parquet('s3://ws-10-8-21/eval_t_1000.parquet')\n",
    "sample = wr.s3.read_parquet('s3://ws-10-8-21/sample.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3aa469",
   "metadata": {},
   "source": [
    "We make the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e1c48d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(sample['phrase'], sample['sentiment'], test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d0618",
   "metadata": {},
   "source": [
    "\n",
    "Transformers models like BERT and DistilBERT use tokenization, that is, the words are broken down into 'sub-words' called tokens and Hugging Face provides pre-trained tokenizers that we use below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4be937b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ac16fd923f4efda3e47d5ff9221c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e000ad0cff434cdd99ab35c930fdc045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8638fd12084b0f90cb322d2aa49cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116dcb5cb77b45dc80def89be7688b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f6cb8c",
   "metadata": {},
   "source": [
    "The data is tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "282cf1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_texts = eval_t_1000['phrase']\n",
    "eval_labels = eval_t_1000['sentiment']\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
    "eval_encodings = tokenizer(list(eval_texts), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f48087",
   "metadata": {},
   "source": [
    "We need a `Dataset` object to feed to the Pytorch `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdc1c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RUDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = RUDataset(train_encodings, list(train_labels))\n",
    "val_dataset = RUDataset(test_encodings, list(test_labels))\n",
    "eval_dataset = RUDataset(eval_encodings, list(eval_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ce22f",
   "metadata": {},
   "source": [
    "Finally, we  load the pre-trained `distilbert` model below which should require less resources to train than a full BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93bbde",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "We pass the `train_dataset` to the `Dataloader` which we use to iterate over the batches. We restarted Sagemaker with a `ml.g4dn.xlarge` and then ran the training for one epoch. We have a batch size of 128 to suit the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c880ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53237ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(1):\n",
    "    for batch in train_loader:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffda20c",
   "metadata": {},
   "source": [
    "We saved the model so that we can start from the saved model when running the notebook again on cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab793577",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = './model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optim.state_dict()\n",
    "    }, output_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853eb8b",
   "metadata": {},
   "source": [
    "Then load the model to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e14d9f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(output_model, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b709783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c64c0b",
   "metadata": {},
   "source": [
    "We again use a `Transformers pipeline` to get the sentiment from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "530c9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ea05d",
   "metadata": {},
   "source": [
    "Let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b3ef27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.5034525990486145}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('transformers roll out')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe2e447",
   "metadata": {},
   "source": [
    "We write a function to make it easy to apply to the dataframe when evaluating later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30b86cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_transformer_sentiment(text):\n",
    "    s = 1\n",
    "    if sentiment(text)[0]['label'] == 'LABEL_0':\n",
    "        s = 0\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4647e0be",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "Let's test out the models on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c94021b",
   "metadata": {},
   "source": [
    "# Multi-class performance of compositional model\n",
    "Let's load the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b72f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_1000 = wr.s3.read_parquet('s3://ws-10-8-21/eval_1000.parquet')\n",
    "eval = eval_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92fb2e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice episode bohat acha h darama 1st time itna...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newscaster bhai practice ker k aya kro lgta hy...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poor imran chanday se rah gaya.garbage collect...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First class cricket mein bhi Intikhab Alam ke ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kaisy batein Kar ry ho?</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>G ni is din mny kch Ni kaha m SOI Hui thi</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Bus kar Yar ye Kia isue banaya</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Every one should abide the Rule of Law .</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Hahahaha actually main nazar nhi aata</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>School ki taleem mukammal karne ke bad Hussai...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                phrase sentiment  \\\n",
       "0    Nice episode bohat acha h darama 1st time itna...  Positive   \n",
       "1    Newscaster bhai practice ker k aya kro lgta hy...  Positive   \n",
       "2    Poor imran chanday se rah gaya.garbage collect...  Negative   \n",
       "3    First class cricket mein bhi Intikhab Alam ke ...  Positive   \n",
       "4                             Kaisy batein Kar ry ho?    Neutral   \n",
       "..                                                 ...       ...   \n",
       "995          G ni is din mny kch Ni kaha m SOI Hui thi   Neutral   \n",
       "996                     Bus kar Yar ye Kia isue banaya  Positive   \n",
       "997           Every one should abide the Rule of Law .   Neutral   \n",
       "998             Hahahaha actually main nazar nhi aata    Neutral   \n",
       "999   School ki taleem mukammal karne ke bad Hussai...   Neutral   \n",
       "\n",
       "    predicted_sentiment  \n",
       "0              Positive  \n",
       "1              Negative  \n",
       "2              Negative  \n",
       "3               Neutral  \n",
       "4               Neutral  \n",
       "..                  ...  \n",
       "995             Neutral  \n",
       "996             Neutral  \n",
       "997             Neutral  \n",
       "998             Neutral  \n",
       "999             Neutral  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54647a",
   "metadata": {},
   "source": [
    "The multi-class confusion matrix is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24c8ca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.51      0.34      0.41       283\n",
      "     Neutral       0.48      0.75      0.58       417\n",
      "    Positive       0.65      0.34      0.44       300\n",
      "\n",
      "    accuracy                           0.51      1000\n",
      "   macro avg       0.55      0.48      0.48      1000\n",
      "weighted avg       0.54      0.51      0.49      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true = eval['sentiment']\n",
    "predicted = eval['predicted_sentiment']\n",
    "print(sklearn.metrics.classification_report(true,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e56ddde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(true, predicted, labels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = [\"Negative\", \"Neutral\", \"Positive\"])\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ffeac97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: Of the 283 negative examples in the test set, the model correctly labeled 97 (34.300000000000004%).\n",
      "Recall: Of the 417 neutral examples in the test set, the model correctly labeled 312 (74.8%).\n",
      "Recall: Of the 300 positive examples in the test set, the model correctly labeled 101 (33.7%).\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recall: Of the {sum(cm[0])} negative examples in the test set, the model correctly labeled {cm[0][0]} ({100*round(cm[0][0]/sum(cm[0]),3)}%).\")\n",
    "print(f\"Recall: Of the {sum(cm[1])} neutral examples in the test set, the model correctly labeled {cm[1][1]} ({100*round(cm[1][1]/sum(cm[1]),3)}%).\")\n",
    "print(f\"Recall: Of the {sum(cm[2])} positive examples in the test set, the model correctly labeled {cm[2][2]} ({100*round(cm[2][2]/sum(cm[2]),3)}%).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5798a9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 examples labeled negative in the test set.\n",
      "The model correctly labeled 97 of them.\n",
      "Precision: The negative predictive value is 0.51\n",
      "The proportion of Negative text is 0.283\n"
     ]
    }
   ],
   "source": [
    "print(f'{cm[0][0]+cm[1][0]+cm[2][0]} examples labeled negative in the test set.')\n",
    "print(f'The model correctly labeled {cm[0][0]} of them.')\n",
    "print(f'Precision: The negative predictive value is {round(cm[0][0]/(cm[0][0]+cm[1][0]+cm[2][0]),2)}')\n",
    "print(f'The proportion of Negative text is {sum(cm[0])/len(eval)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b3ac8",
   "metadata": {},
   "source": [
    "# Binary classification performance of compositional model\n",
    "We classify text as positive or negative on the subset of the dataset consisting of such values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de8ee465",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_b = wr.s3.read_parquet('s3://ws-10-8-21/eval_b_1000.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf3b52fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In conferences mein khawateen ke infaradi masa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab inhe aik aur aezaaz hasil hua hai</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Us dauran unhe kae kohna mushq aur tajurbakaa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aap zaroor hissa lay.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ach sory muh seda</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Runs banne lage</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Aglay din aakhir kaar classes, aik adad halo m...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Masha Allah cute nice Both. Mola Salamt or Kho...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Bashak mgr ak bat aurat khati wo kon ha jas kh...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Hussain haqani jese afraad ko sakht tareen saz...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                phrase sentiment  \\\n",
       "0    In conferences mein khawateen ke infaradi masa...  Positive   \n",
       "1                 Ab inhe aik aur aezaaz hasil hua hai  Positive   \n",
       "2     Us dauran unhe kae kohna mushq aur tajurbakaa...  Positive   \n",
       "3                               aap zaroor hissa lay.   Positive   \n",
       "4                                    ach sory muh seda  Negative   \n",
       "..                                                 ...       ...   \n",
       "995                                    Runs banne lage  Positive   \n",
       "996  Aglay din aakhir kaar classes, aik adad halo m...  Negative   \n",
       "997  Masha Allah cute nice Both. Mola Salamt or Kho...  Positive   \n",
       "998  Bashak mgr ak bat aurat khati wo kon ha jas kh...  Negative   \n",
       "999  Hussain haqani jese afraad ko sakht tareen saz...  Negative   \n",
       "\n",
       "    predicted_sentiment  \n",
       "0              Positive  \n",
       "1              Positive  \n",
       "2              Positive  \n",
       "3              Negative  \n",
       "4              Negative  \n",
       "..                  ...  \n",
       "995            Negative  \n",
       "996            Negative  \n",
       "997            Positive  \n",
       "998            Negative  \n",
       "999            Negative  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae87bf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.68      0.73      0.71       462\n",
      "    Positive       0.75      0.71      0.73       538\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.72      0.72      0.72      1000\n",
      "weighted avg       0.72      0.72      0.72      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(eval_b['sentiment'],eval_b['predicted_sentiment'], target_names=['Negative','Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "460bcbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true = eval_b['sentiment']\n",
    "predicted = eval_b['predicted_sentiment']\n",
    "cm = sklearn.metrics.confusion_matrix(true, predicted, labels=[\"Negative\", \"Positive\"])\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"Negative\", \"Positive\"])\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0472900",
   "metadata": {},
   "source": [
    "# Binary classification performance of transformer model\n",
    "We classify text as positive or negative on the subset of the dataset consisting of such values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f471f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_b_HF = wr.s3.read_parquet('s3://ws-10-8-21/eval_b_1000_HF.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31f13699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bht nikly mere armaan lekin phir b km nikly</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferdous ki lawn ap ki hoi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mam ap Kay lay.........</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ya Allah madam farma</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mghy boht boht boht duaon ke zrort hy</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Chha gya mery cheetah</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ya ya.. they have all rights to do that with o...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Wrna Pakistani dramon mai sivaay rone dhone k ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Kal to Maara tha</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Lyari Lee Market Salaar Compound Aur Aitraf Me...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                phrase sentiment  \\\n",
       "0         bht nikly mere armaan lekin phir b km nikly   Negative   \n",
       "1                            Ferdous ki lawn ap ki hoi  Positive   \n",
       "2                              Mam ap Kay lay.........  Positive   \n",
       "3                                 Ya Allah madam farma  Positive   \n",
       "4                Mghy boht boht boht duaon ke zrort hy  Positive   \n",
       "..                                                 ...       ...   \n",
       "995                              Chha gya mery cheetah  Positive   \n",
       "996  ya ya.. they have all rights to do that with o...  Positive   \n",
       "997  Wrna Pakistani dramon mai sivaay rone dhone k ...  Positive   \n",
       "998                                  Kal to Maara tha   Negative   \n",
       "999  Lyari Lee Market Salaar Compound Aur Aitraf Me...  Negative   \n",
       "\n",
       "    predicted_sentiment  \n",
       "0              Negative  \n",
       "1              Positive  \n",
       "2              Positive  \n",
       "3              Positive  \n",
       "4              Negative  \n",
       "..                  ...  \n",
       "995            Positive  \n",
       "996            Negative  \n",
       "997            Positive  \n",
       "998            Negative  \n",
       "999            Negative  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_b_HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32fc4d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      0.73      0.67       485\n",
      "    Positive       0.69      0.57      0.62       515\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.65      0.65      0.65      1000\n",
      "weighted avg       0.66      0.65      0.65      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(eval_b_HF['sentiment'],eval_b_HF['predicted_sentiment'], target_names=['Negative','Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88d77c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true = eval_b_HF['sentiment']\n",
    "predicted = eval_b_HF['predicted_sentiment']\n",
    "cm = sklearn.metrics.confusion_matrix(true, predicted, labels=[\"Negative\", \"Positive\"])\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[\"Negative\", \"Positive\"])\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3dc54e",
   "metadata": {},
   "source": [
    "# Binary classification with the trained transformer model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ff52bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_t_transformer = wr.s3.read_parquet('s3://ws-10-8-21/eval_t_1000_sentiment.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "609bda3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sooo soooo nice katni ki h ya</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heheheheheheh yakeen mano mera notification pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qiamat e sughra kay iss manzar kay dauran Ben...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aur pas chli ja</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Duao ki zaroorat dua ki jia ga</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Allama Raghib Ahsan ne 1931 mein “ all india ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>mjhy ye zyada achy lgy hn unsy... anum</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Turbat Se 3 Tashaddud Zada Lashen Baramad</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Kash mugha b koi ece trah mot ke khabar dane aata</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>miss those midnight snacks 😄</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                phrase  sentiment  \\\n",
       "0                        Sooo soooo nice katni ki h ya          0   \n",
       "1    Heheheheheheh yakeen mano mera notification pa...          0   \n",
       "2     Qiamat e sughra kay iss manzar kay dauran Ben...          1   \n",
       "3                                     Aur pas chli ja           1   \n",
       "4                       Duao ki zaroorat dua ki jia ga          0   \n",
       "..                                                 ...        ...   \n",
       "995   Allama Raghib Ahsan ne 1931 mein “ all india ...          0   \n",
       "996             mjhy ye zyada achy lgy hn unsy... anum          0   \n",
       "997         Turbat Se 3 Tashaddud Zada Lashen Baramad           1   \n",
       "998  Kash mugha b koi ece trah mot ke khabar dane aata          1   \n",
       "999                       miss those midnight snacks 😄          0   \n",
       "\n",
       "     predicted_sentiment  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "..                   ...  \n",
       "995                    0  \n",
       "996                    0  \n",
       "997                    0  \n",
       "998                    0  \n",
       "999                    0  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_t_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30c61654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        0.014000\n",
       "std         0.117549\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000\n",
       "Name: predicted_sentiment, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_t_transformer['predicted_sentiment'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253f21f",
   "metadata": {},
   "source": [
    "Clearly, as most of the values are 0, training the pre-trained model on the dataset reduced performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb36880",
   "metadata": {},
   "source": [
    "# ETL\n",
    "**All remaining code in the notebook only needs to be ran once.**\n",
    "\n",
    "We make a directory to store the original data in case the [website](http://archive.ics.uci.edu/ml/datasets/Roman+Urdu+Data+Set) which is serving it becomes unavailable or updates to a version which is inconsistent with our code.\n",
    "We download the data with `wget` and add it to the directory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8dbf828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-01-21 15:00:27--  http://archive.ics.uci.edu/ml/machine-learning-databases/00458/Roman%20Urdu%20DataSet.csv\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1628349 (1.6M) [application/x-httpd-php]\n",
      "Saving to: ‘original-data.csv’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  3%  330K 5s\n",
      "    50K .......... .......... .......... .......... ..........  6%  697K 3s\n",
      "   100K .......... .......... .......... .......... ..........  9%  184M 2s\n",
      "   150K .......... .......... .......... .......... .......... 12%  303M 2s\n",
      "   200K .......... .......... .......... .......... .......... 15%  727K 2s\n",
      "   250K .......... .......... .......... .......... .......... 18% 69.2M 1s\n",
      "   300K .......... .......... .......... .......... .......... 22% 80.1M 1s\n",
      "   350K .......... .......... .......... .......... .......... 25% 88.5M 1s\n",
      "   400K .......... .......... .......... .......... .......... 28%  752K 1s\n",
      "   450K .......... .......... .......... .......... .......... 31% 57.3M 1s\n",
      "   500K .......... .......... .......... .......... .......... 34% 67.2M 1s\n",
      "   550K .......... .......... .......... .......... .......... 37%  105M 1s\n",
      "   600K .......... .......... .......... .......... .......... 40%  111M 1s\n",
      "   650K .......... .......... .......... .......... .......... 44%  105M 0s\n",
      "   700K .......... .......... .......... .......... .......... 47%  105M 0s\n",
      "   750K .......... .......... .......... .......... .......... 50%  120M 0s\n",
      "   800K .......... .......... .......... .......... .......... 53% 88.9M 0s\n",
      "   850K .......... .......... .......... .......... .......... 56%  767K 0s\n",
      "   900K .......... .......... .......... .......... .......... 59%  328M 0s\n",
      "   950K .......... .......... .......... .......... .......... 62%  354M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 66%  148M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 69% 82.4M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 72%  128M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 75% 68.4M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 78% 65.2M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 81% 68.8M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 84% 54.1M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 88%  125M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 91% 72.3M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 94% 62.2M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 97% 75.8M 0s\n",
      "  1550K .......... .......... .......... ..........           100% 61.1M=0.4s\n",
      "\n",
      "2022-01-21 15:00:28 (3.54 MB/s) - ‘original-data.csv’ saved [1628349/1628349]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir original-data\n",
    "cd original-data\n",
    "wget http://archive.ics.uci.edu/ml/machine-learning-databases/00458/Roman%20Urdu%20DataSet.csv -O original-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def62d77",
   "metadata": {},
   "source": [
    "We load the data into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a97c3",
   "metadata": {},
   "source": [
    "Since we were advised not to use GitHub, we'll sync our notebook directory with a new S3 bucket so that we have a backup of the data in case we lose our notebook instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a82bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: .ipynb_checkpoints/roman-urdu-nlp-checkpoint.html to s3://roman-urdu-nlp/.ipynb_checkpoints/roman-urdu-nlp-checkpoint.html\n",
      "upload: ./roman-urdu-nlp.ipynb to s3://roman-urdu-nlp/roman-urdu-nlp.ipynb\n",
      "upload: ./roman-urdu-nlp.html to s3://roman-urdu-nlp/roman-urdu-nlp.html\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "aws s3 sync . s3://roman-urdu-nlp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939bf8f2",
   "metadata": {},
   "source": [
    "Now we load the data into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('s3://ws-10-8-21/original-data/original-data.csv', header=None,names=['phrase','sentiment'], index_col=False,dtype={'phrase': 'string','sentiment':'category'}, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b88423d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phrase         string\n",
       "sentiment    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4584e8",
   "metadata": {},
   "source": [
    "We see below that the dataframe headers and indices are correctly formatted and ready for further preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b982ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sai kha ya her kisi kay bus ki bat nhi hai lak...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sahi bt h</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kya bt hai,</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wah je wah</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are wha kaya bat hai</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase sentiment\n",
       "0  Sai kha ya her kisi kay bus ki bat nhi hai lak...  Positive\n",
       "1                                          sahi bt h  Positive\n",
       "2                                        Kya bt hai,  Positive\n",
       "3                                         Wah je wah  Positive\n",
       "4                               Are wha kaya bat hai  Positive"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f75006a",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "We are expecting, according to the [website hosting the data](http://archive.ics.uci.edu/ml/datasets/Roman+Urdu+Data+Set), there to be three classes, as the site writes \"Tagged for Sentiment (Positive, Negative, Neutral)\".\n",
    "\n",
    "We see immediately that there is an issue as there are 4 unique values in sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a1eae09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20228</td>\n",
       "      <td>20229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19664</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Good</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>23</td>\n",
       "      <td>8929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       phrase sentiment\n",
       "count   20228     20229\n",
       "unique  19664         4\n",
       "top      Good   Neutral\n",
       "freq       23      8929"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0f863",
   "metadata": {},
   "source": [
    "Let's fix that. First we need to find these rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5485eb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13277</th>\n",
       "      <td>product achi hai but wrong waist size send kar...</td>\n",
       "      <td>Neative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  phrase sentiment\n",
       "13277  product achi hai but wrong waist size send kar...   Neative"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.sentiment.isin(['Neutral','Positive','Negative'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980b09f",
   "metadata": {},
   "source": [
    "We see there is one row with a mispelled sentiment. Clearly they meant \"Negative\" here, so we  will update that and keep it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63f27835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[13277], ['sentiment']] = 'Negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055e3f4",
   "metadata": {},
   "source": [
    "Let's check that it is correct now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5dc5f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13277</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment\n",
       "13277  Negative"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[13277], ['sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e994f07",
   "metadata": {},
   "source": [
    "Let's make sure there are now three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5754cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20228</td>\n",
       "      <td>20229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19664</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Good</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>23</td>\n",
       "      <td>8929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       phrase sentiment\n",
       "count   20228     20229\n",
       "unique  19664         3\n",
       "top      Good   Neutral\n",
       "freq       23      8929"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4f0348",
   "metadata": {},
   "source": [
    "Another issue is that `phrase` has a count of 20228, while `sentiment` is one higher. Let's fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1b044ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16904</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phrase sentiment\n",
       "16904   <NA>   Neutral"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df['phrase'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e70f3f",
   "metadata": {},
   "source": [
    "As we have no idea of knowing what the phrase could have been, we remove this row from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0548dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([16904])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a6bd5",
   "metadata": {},
   "source": [
    "Make sure it is correct now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d7c72d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20228</td>\n",
       "      <td>20228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19664</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Good</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>23</td>\n",
       "      <td>8928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       phrase sentiment\n",
       "count   20228     20228\n",
       "unique  19664         3\n",
       "top      Good   Neutral\n",
       "freq       23      8928"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c7a7e",
   "metadata": {},
   "source": [
    "Let's check if there are any more `NaN` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "798dd03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['phrase'].hasnans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea61048c",
   "metadata": {},
   "source": [
    "Since the data is now clean and ready for analysis, let's save a copy to S3 for later access. We save in the Parquet format to ensure the information on data types in the columns is maintained. There is  a tool for doing so directly called AWS Data Wrangler. We use it to save to parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02b5c6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://ws-10-8-21/clean-data.parquet'], 'partitions_values': {}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.s3.to_parquet(df, 's3://ws-10-8-21/clean-data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124fc812",
   "metadata": {},
   "source": [
    "Finally, let's check that it was formatted correctly by loading into a new dataframe. Unexpectedly, if you try to read it with`dfc = pd.read_csv(\"s3://ws-10-8-21/clean-data.csv\")` you will get an error of `ParserError: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.` A solution is to change the *engine* to Python. Even then, you will find that the process of loading to and reading from S3 for this dataset in csv format is not idempotent in the sense that each time it will introduce two NaN values into the `phrase` column. We continue then in parquet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ce9da",
   "metadata": {},
   "source": [
    "## Loading clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9fc866d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = wr.s3.read_parquet('s3://ws-10-8-21/clean-data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7f809",
   "metadata": {},
   "source": [
    "## Creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_texts =\n",
    "dfc_b = dfc[dfc['sentiment']!='Neutral'] # binarize\n",
    "dfc_b['sentiment'] = dfc_b['sentiment'].factorize()[0] #convert to numeric for PyTorch\n",
    "eval_t_1000 = dfc_b.sample(1000) #sample 1000 for comparison to other models\n",
    "sample = dfc_b[~dfc_b.index.isin(eval_t_1000.index)] #take complement for train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd0de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.s3.to_parquet(eval_t_1000, 's3://ws-10-8-21/eval_t_1000.parquet') # save to S3\n",
    "wr.s3.to_parquet(sample, 's3://ws-10-8-21/sample.parquet') # save to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0fa2077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10300\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(sample))\n",
    "print(len(eval_t_1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff09c6b",
   "metadata": {},
   "source": [
    "## Preparing testing data\n",
    "\n",
    "### Multiclass testing data\n",
    "We sample 1000 rows from the dataset, apply the multiclass classifier, and write the data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4def68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval = dfc.sample(1000)\n",
    "eval['predicted_sentiment'] = eval['phrase'].apply(sentiment_roman_urdu)\n",
    "wr.s3.to_parquet(eval, 's3://ws-10-8-21/eval_1000.parquet') # save to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93520f35",
   "metadata": {},
   "source": [
    "### Binary testing data\n",
    "We sample 1000 rows from the binarized dataset, apply the binary classifier, and write the data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d37634",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfc_b = dfc[dfc['sentiment']!='Neutral']  #remove neutrals from dataset\n",
    "eval_b = dfc_b.sample(1000)\n",
    "eval_b['predicted_sentiment'] = eval_b['phrase'].apply(binary_sentiment_roman_urdu)\n",
    "wr.s3.to_parquet(eval_b, 's3://ws-10-8-21/eval_b_1000.parquet') # save to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a06a1",
   "metadata": {},
   "source": [
    "### Transformer testing data\n",
    "We sample 1000 rows from the binarized dataset, apply the transformer binary classifier, and write the data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfc_b = dfc[dfc['sentiment']!='Neutral']  #remove neutrals from dataset\n",
    "eval_b_HF = dfc_b.sample(1000)\n",
    "eval_b_HF['predicted_sentiment'] = eval_b_HF['phrase'].apply(binary_sentiment_roman_urdu_HF)\n",
    "wr.s3.to_parquet(eval_b_HF, 's3://ws-10-8-21/eval_b_1000_HF.parquet') # save to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818512d2",
   "metadata": {},
   "source": [
    "### Trained transformer testing data\n",
    "We read the evaluation data, then apply the trained transformer model and write the data to S#."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9296c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval_t_transformer = wr.s3.read_parquet('s3://ws-10-8-21/eval_t_1000_sentiment.parquet')\n",
    "eval_t_1000['predicted_sentiment'] = eval_t_1000['phrase'].apply(binary_transformer_sentiment)\n",
    "wr.s3.to_parquet(eval_t_1000, 's3://ws-10-8-21/eval_t_1000_sentiment.parquet') # save to S3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
